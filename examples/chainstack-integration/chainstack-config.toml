# Comprehensive Chainstack Yellowstone gRPC Configuration
# This configuration demonstrates all available options for the
# Chainstack integration with complete production settings.

[chainstack]
# Environment configuration
active_environment = "prod"

# Production environment
[chainstack.environments.prod]
name = "production"
endpoint = "https://nd-123-456-789.p2pify.com"
api_key = "${CHAINSTACK_API_KEY}"

[chainstack.environments.prod.custom_headers]
"X-Client-Name" = "yellowstone-vixen"
"X-Client-Version" = "1.0.0"

# Staging environment
[chainstack.environments.staging]
name = "staging"
endpoint = "https://nd-123-456-789.staging.p2pify.com"
api_key = "${CHAINSTACK_STAGING_API_KEY}"

# Development environment
[chainstack.environments.dev]
name = "development"
endpoint = "https://nd-123-456-789.dev.p2pify.com"
api_key = "${CHAINSTACK_DEV_API_KEY}"

# Connection pool configuration
[chainstack.connection_pool]
max_connections_per_filter = 5
connection_timeout_secs = 30
keep_alive_interval_secs = 30
max_idle_secs = 300

# Circuit breaker configuration
[chainstack.circuit_breaker]
failure_threshold = 5
half_open_timeout_secs = 60
success_threshold = 3
max_open_wait_secs = 300

# Retry policy configuration
[chainstack.retry_policy]
max_retries = 3
initial_backoff_ms = 1000
max_backoff_ms = 30000
backoff_multiplier = 2.0
jitter_factor = 0.1

# Redis streaming configuration
[redis]
[redis.cluster]
url = "redis://localhost:6379"
# For Redis cluster mode:
# nodes = ["redis-1:6379", "redis-2:6379", "redis-3:6379"]
pool_size = 20
connect_timeout_ms = 5000
command_timeout_ms = 1000

# Stream configurations for different data types
[redis.streams]
[redis.streams.accounts]
name = "solana_accounts"
max_length = 1000000
retention_seconds = 86400  # 24 hours
partition_strategy = "ByAccount"

[redis.streams.transactions]
name = "solana_transactions"
max_length = 1000000
retention_seconds = 86400
partition_strategy = "BySignature"

[redis.streams.blocks]
name = "solana_blocks"
max_length = 100000
retention_seconds = 604800  # 7 days
partition_strategy = "Single"

[redis.streams.trade_events]
name = "trade_events"
max_length = 5000000
retention_seconds = 2592000  # 30 days
partition_strategy = "ByAccount"

# Consumer group configurations
[redis.consumer_groups]
[redis.consumer_groups.trading_pipeline]
group_name = "trading_pipeline"
consumer_count = 4
block_ms = 1000
max_pending = 10000

[redis.consumer_groups.analytics_pipeline]
group_name = "analytics_pipeline" 
consumer_count = 2
block_ms = 5000
max_pending = 5000

# Buffer configuration for high-throughput processing
[buffer]
[buffer.channel_sizes]
source_to_parser = 10000
parser_to_handler = 10000
handler_to_redis = 10000
error_channel = 1000

[buffer.worker_pools]
parser_workers = 8
handler_workers = 8
redis_workers = 4
worker_timeout_secs = 30

[buffer.batching]
redis_batch_size = 1000
batch_timeout_ms = 100
memory_pressure_threshold = 50000

# Monitoring and observability configuration
[monitoring]
enabled = true

[monitoring.metrics]
collection_interval_secs = 10

[monitoring.metrics.prometheus]
endpoint = "http://localhost:9091"
path = "/metrics"
export_interval_secs = 15

[monitoring.metrics.prometheus.labels]
environment = "production"
service = "chainstack-pipeline"
version = "1.0.0"

[[monitoring.metrics.custom_backends]]
name = "datadog"
endpoint = "https://api.datadoghq.com/api/v1/series"
[monitoring.metrics.custom_backends.auth]
auth_type = "ApiKey"
[monitoring.metrics.custom_backends.auth.credentials]
api_key = "${DATADOG_API_KEY}"

[monitoring.tracing]
level = "info"

[monitoring.tracing.opentelemetry]
endpoint = "http://localhost:4317"
service_name = "chainstack-vixen-pipeline"

[monitoring.tracing.opentelemetry.attributes]
environment = "production"
team = "trading"

[monitoring.health_checks]
enabled = true
port = 8081
interval_secs = 30
timeout_secs = 10

[[monitoring.health_checks.custom_checks]]
name = "chainstack_connectivity"
[monitoring.health_checks.custom_checks.config]
endpoint = "https://nd-123-456-789.p2pify.com"
timeout_ms = 5000

# Security configuration
[security]
[security.api_keys]
rotation_enabled = true
rotation_interval_hours = 24
storage_backend = "Environment"

[security.tls]
enabled = true
verify_server = true
# cert_path = "/path/to/cert.pem"
# key_path = "/path/to/key.pem"
# ca_path = "/path/to/ca.pem"

[security.rate_limiting]
enabled = true
requests_per_second = 1000
burst_capacity = 2000
strategy = "TokenBucket"

# Filter presets for different trading scenarios
[[filter_presets]]
name = "high_volume_trading"
description = "Monitor high-volume trading across all DEXs"
[filter_presets.transaction_filter]
programs_include = [
    "JUP6LkbZbjS1jKKwapdHNy74zcZ3tLUZoi5QNyVTaV4",  # Jupiter V6
    "675kPX9MHTjS2zt1qfr1NYHuzeLXfQM9H24wFSUt1Mp8",  # Raydium AMM V4
    "CAMMCzo5YL8w4VFF8KVHrK22GGUQpMNRqTFXP3K4M8oX",  # Raydium CLMM
    "whirLbMiicVdio4qvUfM5KAg6Ct8VwpYzGff3uctyCc",   # Orca Whirlpool
    "6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ14M5uBEwF6P",   # Pump.fun
]
fee_range = [5000, 50000000]  # 0.005 to 50 SOL fees
include_failed = false

[[filter_presets]]
name = "whale_watching"
description = "Monitor large transactions from known whale wallets"
[filter_presets.transaction_filter]
accounts_include = [
    "DYw8jCTfwHNRJhhmFcbXvVDTqWMEVFBX6ZKUmG5CNSKK",  # Example whale wallet 1
    "9WzDXwBbmkg8ZTbNMqUxvQRAyrZzDsGYdLVL9zYtAWWM",  # Example whale wallet 2
]
fee_range = [10000000, 1000000000]  # 0.01 to 1000 SOL fees

[[filter_presets]]
name = "meme_token_monitoring"
description = "Monitor meme token launches and trading"
[filter_presets.transaction_filter]
programs_include = [
    "6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ14M5uBEwF6P",   # Pump.fun
    "TokioRqRBLK8a6CaJJaHkdpWBgkJHH1s1YdoLEGo8c",   # Custom meme program
]

[[filter_presets]]
name = "defi_yield_farming"
description = "Monitor DeFi yield farming and liquidity provision"
[filter_presets.transaction_filter]
programs_include = [
    "675kPX9MHTjS2zt1qfr1NYHuzeLXfQM9H24wFSUt1Mp8",  # Raydium AMM V4
    "CLMM9tUoggJu2wagPkkqs9eFG4BWhVBZWkP1qv3Sp7tR",  # Meteora CLMM
    "LBUZKhRxPF3XUpBCjp4YzTKgLccjZhTSDM9YuVaPwxo",   # Meteora Pools
]

# Performance tuning
[performance]
# Connection settings
max_concurrent_requests = 100
request_timeout_secs = 30
keepalive_timeout_secs = 60

# Memory management
max_memory_usage_mb = 2048
gc_threshold_mb = 1536
buffer_pool_size = 1000

# Disk usage (for local caching)
cache_dir = "/tmp/yellowstone-cache"
max_cache_size_mb = 5120
cache_ttl_secs = 3600

# Logging configuration
[logging]
level = "info"
format = "json"
output = ["stdout", "file"]

[logging.file]
path = "/var/log/chainstack-pipeline.log"
max_size_mb = 100
max_backups = 10
max_age_days = 7
compress = true

[logging.sampling]
enabled = true
initial = 100
thereafter = 100

# Development and testing overrides
[development]
# Override settings for development environment
mock_chainstack = false
enable_debug_logging = true
disable_rate_limiting = true
reduced_buffer_sizes = true

[testing]
# Settings for integration testing
use_test_redis = true
test_redis_url = "redis://localhost:6380"
mock_trading_data = true
fast_shutdown = true